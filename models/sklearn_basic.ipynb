{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "\n",
    "# sklearn imports for preprocessing and model building\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    roc_auc_score,\n",
    ")\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder, PolynomialFeatures, StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tabulate import tabulate\n",
    "\n",
    "sys.path.insert(0, \"../utils\")\n",
    "import utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import csv to df\n",
    "df = pd.read_csv(\"../data/renttherunway_cleaned_data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results dataframe\n",
    "results = pd.DataFrame(\n",
    "    columns=[\n",
    "        \"model\",\n",
    "        \"accuracy\",\n",
    "        \"precision\",\n",
    "        \"recall\",\n",
    "        \"f1\",\n",
    "        \"mse\",\n",
    "        \"ber\",\n",
    "        \"mae\",\n",
    "        \"best_params\",\n",
    "        \"best_estimator\",\n",
    "        \"feature_importances\",\n",
    "        \"confusion_matrix\",\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression_model(\n",
    "    data, model_class, full_grid_search=False, param_grid=None, **kwargs\n",
    "):\n",
    "    # Label Encoding for categorical variables\n",
    "    label_encoders = {}\n",
    "    categorical_cols = [\n",
    "        \"bust size\",\n",
    "        \"rented for\",\n",
    "        \"body type\",\n",
    "        \"category\",\n",
    "        \"cup_size\",\n",
    "        \"fit\",\n",
    "    ]\n",
    "    for col in categorical_cols:\n",
    "        le = LabelEncoder()\n",
    "        data[col] = le.fit_transform(data[col].astype(str))\n",
    "        label_encoders[col] = le\n",
    "\n",
    "    # Feature columns\n",
    "    feature_cols = [\n",
    "        \"fit\",\n",
    "        \"user_id\",\n",
    "        \"bust size\",\n",
    "        \"item_id\",\n",
    "        \"weight\",\n",
    "        \"rented for\",\n",
    "        \"body type\",\n",
    "        \"category\",\n",
    "        \"height\",\n",
    "        \"size\",\n",
    "        \"age\",\n",
    "        \"review_length\",\n",
    "        \"band_size\",\n",
    "        \"cup_size\",\n",
    "    ]\n",
    "\n",
    "    # Impute missing values\n",
    "    imputer = SimpleImputer(strategy=\"mean\")\n",
    "    data[feature_cols] = imputer.fit_transform(data[feature_cols])\n",
    "\n",
    "    data = data.dropna(subset=[\"rating\"])\n",
    "\n",
    "    # Splitting the dataset\n",
    "    X = data[feature_cols]\n",
    "\n",
    "    def map_rating_to_label(rating):\n",
    "        rating_mapping = {2.0: 0, 4.0: 1, 6.0: 2, 8.0: 3, 10.0: 4}\n",
    "        return rating_mapping.get(rating, 5)  # 5 is the label for 'others'\n",
    "\n",
    "    y = data[\"rating\"].apply(map_rating_to_label)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=42\n",
    "    )\n",
    "\n",
    "    # Scaling features\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    # Ignore sklearn warnings\n",
    "    import warnings\n",
    "\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "    # Grid Search with Cross-Validation\n",
    "    if full_grid_search:\n",
    "        grid_search = GridSearchCV(\n",
    "            model_class(), param_grid, cv=5, scoring=\"accuracy\", verbose=1\n",
    "        )\n",
    "        grid_search.fit(X_train, y_train)\n",
    "\n",
    "        best_model = grid_search.best_estimator_\n",
    "        print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "        print(f\"Best cross-validation score: {grid_search.best_score_}\")\n",
    "    else:\n",
    "        best_model = model_class(**kwargs)\n",
    "        # best_model = LogisticRegression(C=0.01, class_weight='balanced', penalty='l1', solver='liblinear')\n",
    "        best_model.fit(X_train, y_train)\n",
    "\n",
    "    # Feature Importance Analysis\n",
    "    # Get coefficients and calculate odds ratios\n",
    "    try:\n",
    "        coefficients = best_model.coef_[0]\n",
    "        odds_ratios = np.exp(coefficients)\n",
    "    except AttributeError:\n",
    "        coefficients = best_model.feature_importances_\n",
    "        odds_ratios = coefficients\n",
    "\n",
    "    # Make feature importance string of format (feature, odds_ratio)\n",
    "    feature_importances = \"\"\n",
    "    for i in range(len(feature_cols)):\n",
    "        feature_importances += (\n",
    "            \"(\" + feature_cols[i] + \", \" + str(odds_ratios[i]) + \")\\n\"\n",
    "        )\n",
    "\n",
    "    # Evaluate on test set\n",
    "    test_score = best_model.score(X_test, y_test)\n",
    "    y_pred = best_model.predict(X_test)\n",
    "\n",
    "    # Save results\n",
    "    mse = np.mean((y_test - y_pred) ** 2)\n",
    "    ber = 1 - test_score\n",
    "    mae = np.mean(np.abs(y_test - y_pred))\n",
    "    f1 = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "    precision = precision_score(y_test, y_pred, average=\"weighted\")\n",
    "    recall = recall_score(y_test, y_pred, average=\"weighted\")\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    if full_grid_search:\n",
    "        best_params = grid_search.best_params_\n",
    "        best_estimator = grid_search.best_estimator_\n",
    "    else:\n",
    "        best_params = kwargs\n",
    "        best_estimator = None\n",
    "    results.loc[len(results)] = [\n",
    "        model_class.__name__,\n",
    "        accuracy,\n",
    "        precision,\n",
    "        recall,\n",
    "        f1,\n",
    "        mse,\n",
    "        ber,\n",
    "        mae,\n",
    "        best_params,\n",
    "        best_estimator,\n",
    "        feature_importances,\n",
    "        confusion_matrix(y_test, y_pred),\n",
    "    ]\n",
    "\n",
    "    # Only print recently appended row of results\n",
    "    print(tabulate(results.iloc[-1:], headers=\"keys\", tablefmt=\"psql\", showindex=False))\n",
    "\n",
    "    return best_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Best parameters: {'C': 0.01, 'class_weight': 'balanced', 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Best cross-validation score: 0.5863364199374198\n",
      "+--------------------+------------+-------------+----------+----------+---------+----------+----------+---------------------------------------------------------------------------------+-------------------------------------------------------------------+-------------------------------------+-----------------------------------+\n",
      "| model              |   accuracy |   precision |   recall |       f1 |     mse |      ber |      mae | best_params                                                                     | best_estimator                                                    | feature_importances                 | confusion_matrix                  |\n",
      "|--------------------+------------+-------------+----------+----------+---------+----------+----------+---------------------------------------------------------------------------------+-------------------------------------------------------------------+-------------------------------------+-----------------------------------|\n",
      "| LogisticRegression |   0.584094 |    0.550657 | 0.584094 | 0.522147 | 1.76996 | 0.415906 | 0.733958 | {'C': 0.01, 'class_weight': 'balanced', 'penalty': 'l1', 'solver': 'liblinear'} | LogisticRegression(C=0.01, class_weight='balanced', penalty='l1', | (fit, 2.2218009465880857)           | [[  121    17     4    15   159]  |\n",
      "|                    |            |             |          |          |         |          |          |                                                                                 |                    solver='liblinear')                            | (user_id, 1.0174922786762628)       |  [  264    49    11    37   499]  |\n",
      "|                    |            |             |          |          |         |          |          |                                                                                 |                                                                   | (bust size, 1.0)                    |  [  655   156    62   186  2087]  |\n",
      "|                    |            |             |          |          |         |          |          |                                                                                 |                                                                   | (item_id, 0.9130219652563661)       |  [ 2069   533   227   761 12502]  |\n",
      "|                    |            |             |          |          |         |          |          |                                                                                 |                                                                   | (weight, 0.9299168701241414)        |  [ 2620   625   295  1053 32732]] |\n",
      "|                    |            |             |          |          |         |          |          |                                                                                 |                                                                   | (rented for, 0.8737398031560909)    |                                   |\n",
      "|                    |            |             |          |          |         |          |          |                                                                                 |                                                                   | (body type, 0.9773202308504203)     |                                   |\n",
      "|                    |            |             |          |          |         |          |          |                                                                                 |                                                                   | (category, 1.0306957551564393)      |                                   |\n",
      "|                    |            |             |          |          |         |          |          |                                                                                 |                                                                   | (height, 0.9722436296532169)        |                                   |\n",
      "|                    |            |             |          |          |         |          |          |                                                                                 |                                                                   | (size, 1.0)                         |                                   |\n",
      "|                    |            |             |          |          |         |          |          |                                                                                 |                                                                   | (age, 1.1337122002849866)           |                                   |\n",
      "|                    |            |             |          |          |         |          |          |                                                                                 |                                                                   | (review_length, 0.6674385289046982) |                                   |\n",
      "|                    |            |             |          |          |         |          |          |                                                                                 |                                                                   | (band_size, 1.0751183388057195)     |                                   |\n",
      "|                    |            |             |          |          |         |          |          |                                                                                 |                                                                   | (cup_size, 1.0025878816938982)      |                                   |\n",
      "+--------------------+------------+-------------+----------+----------+---------+----------+----------+---------------------------------------------------------------------------------+-------------------------------------------------------------------+-------------------------------------+-----------------------------------+\n"
     ]
    }
   ],
   "source": [
    "lr_param_grid = {\n",
    "    \"C\": [0.01, 0.1, 1, 10, 100],\n",
    "    \"penalty\": [\"l1\", \"l2\"],\n",
    "    \"solver\": [\"saga\", \"liblinear\"],\n",
    "    \"class_weight\": [\"balanced\"],\n",
    "}\n",
    "# param_grid = {\n",
    "#     'C': [0.01, 0.1, 1, 10, 100],  # Regularization strength\n",
    "#     'penalty': ['l1', 'l2'],  # Penalty types\n",
    "#     'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],  # Solvers\n",
    "#     'class_weight': [\n",
    "#         {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 1},  # Equal weights\n",
    "#         {0: 2, 1: 1, 2: 1, 3: 1, 4: 1, 5: 1},  # Higher weight for class 0\n",
    "#         {0: 1, 1: 2, 2: 1, 3: 1, 4: 1, 5: 1},  # Higher weight for class 1\n",
    "#         {0: 1, 1: 1, 2: 2, 3: 1, 4: 1, 5: 1},  # Higher weight for class 2\n",
    "#         {0: 1, 1: 1, 2: 1, 3: 2, 4: 1, 5: 1},  # Higher weight for class 3\n",
    "#         {0: 1, 1: 1, 2: 1, 3: 1, 4: 2, 5: 1},  # Higher weight for class 4\n",
    "#         {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 2},  # Higher weight for class 5\n",
    "#         {0: 3, 1: 2, 2: 1, 3: 1, 4: 1, 5: 1},  # Custom weights as an example\n",
    "#         'balanced'  # Automatically compute weights based on class frequencies\n",
    "#     ]\n",
    "# }\n",
    "\n",
    "best_lr_model = logistic_regression_model(\n",
    "    df,\n",
    "    LogisticRegression,\n",
    "    full_grid_search=True,\n",
    "    param_grid=lr_param_grid,\n",
    "    C=0.01,\n",
    "    class_weight=\"balanced\",\n",
    "    penalty=\"l1\",\n",
    "    solver=\"liblinear\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n"
     ]
    }
   ],
   "source": [
    "gbc_param_grid = {\n",
    "    \"n_estimators\": [100, 200, 300],\n",
    "    \"learning_rate\": [0.1, 0.01, 0.001],\n",
    "    \"max_depth\": [3, 5, 7],\n",
    "    \"random_state\": [42],\n",
    "}\n",
    "\n",
    "best_gbc_model = logistic_regression_model(\n",
    "    df,\n",
    "    GradientBoostingClassifier,\n",
    "    full_grid_search=True,\n",
    "    param_grid=gbc_param_grid,\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=3,\n",
    "    random_state=42,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+------------+-------------+----------+----------+----------+----------+----------+-----------------------------------------------------------+------------------+--------------------------------------+-----------------------------------+\n",
      "| model                  |   accuracy |   precision |   recall |       f1 |      mse |      ber |      mae | best_params                                               | best_estimator   | feature_importances                  | confusion_matrix                  |\n",
      "|------------------------+------------+-------------+----------+----------+----------+----------+----------+-----------------------------------------------------------+------------------+--------------------------------------+-----------------------------------|\n",
      "| RandomForestClassifier |   0.646443 |    0.417889 | 0.646443 | 0.507627 | 0.718267 | 0.353557 | 0.454251 | {'n_estimators': 100, 'max_depth': 3, 'random_state': 42} |                  | (fit, 0.6350021728445806)            | [[    0     0     0     0   316]  |\n",
      "|                        |            |             |          |          |          |          |          |                                                           |                  | (user_id, 0.0011439280618751751)     |  [    0     0     0     0   860]  |\n",
      "|                        |            |             |          |          |          |          |          |                                                           |                  | (bust size, 0.00521683335148555)     |  [    0     0     0     0  3146]  |\n",
      "|                        |            |             |          |          |          |          |          |                                                           |                  | (item_id, 0.04449307320886982)       |  [    0     0     0     0 16092]  |\n",
      "|                        |            |             |          |          |          |          |          |                                                           |                  | (weight, 0.011223322610765139)       |  [    0     0     0     0 37325]] |\n",
      "|                        |            |             |          |          |          |          |          |                                                           |                  | (rented for, 0.061311164420504875)   |                                   |\n",
      "|                        |            |             |          |          |          |          |          |                                                           |                  | (body type, 0.0005492560151423712)   |                                   |\n",
      "|                        |            |             |          |          |          |          |          |                                                           |                  | (category, 0.09077322444788519)      |                                   |\n",
      "|                        |            |             |          |          |          |          |          |                                                           |                  | (height, 0.0013115319524910028)      |                                   |\n",
      "|                        |            |             |          |          |          |          |          |                                                           |                  | (size, 0.03150607550234935)          |                                   |\n",
      "|                        |            |             |          |          |          |          |          |                                                           |                  | (age, 0.036120718686017024)          |                                   |\n",
      "|                        |            |             |          |          |          |          |          |                                                           |                  | (review_length, 0.07785430364385594) |                                   |\n",
      "|                        |            |             |          |          |          |          |          |                                                           |                  | (band_size, 0.002782340771460782)    |                                   |\n",
      "|                        |            |             |          |          |          |          |          |                                                           |                  | (cup_size, 0.0007120544827173461)    |                                   |\n",
      "+------------------------+------------+-------------+----------+----------+----------+----------+----------+-----------------------------------------------------------+------------------+--------------------------------------+-----------------------------------+\n"
     ]
    }
   ],
   "source": [
    "rf_param_grid = {\n",
    "    \"n_estimators\": [100, 200, 300],\n",
    "    \"max_depth\": [3, 5, 7],\n",
    "    \"random_state\": [42],\n",
    "}\n",
    "\n",
    "best_rf_model = logistic_regression_model(\n",
    "    df,\n",
    "    RandomForestClassifier,\n",
    "    full_grid_search=True,\n",
    "    param_grid=rf_param_grid,\n",
    "    n_estimators=100,\n",
    "    max_depth=3,\n",
    "    random_state=42,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_param_grid = {\n",
    "    \"C\": [0.1, 1, 10],\n",
    "    \"kernel\": [\"linear\", \"rbf\"],\n",
    "    \"gamma\": [\"scale\", \"auto\"],\n",
    "}\n",
    "\n",
    "best_svc_model = logistic_regression_model(\n",
    "    df,\n",
    "    SVC,\n",
    "    full_grid_search=True,\n",
    "    param_grid=svc_param_grid,\n",
    "    C=1,\n",
    "    kernel=\"rbf\",\n",
    "    gamma=\"scale\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_param_grid = {\n",
    "    \"n_neighbors\": [3, 5, 7],\n",
    "    \"weights\": [\"uniform\", \"distance\"],\n",
    "    \"algorithm\": [\"ball_tree\", \"kd_tree\", \"brute\"],\n",
    "}\n",
    "\n",
    "best_knn_model = logistic_regression_model(\n",
    "    df,\n",
    "    KNeighborsClassifier,\n",
    "    full_grid_search=True,\n",
    "    param_grid=knn_param_grid,\n",
    "    n_neighbors=5,\n",
    "    weights=\"uniform\",\n",
    "    algorithm=\"ball_tree\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_param_grid = {\n",
    "    \"max_depth\": [3, 5, 7, None],\n",
    "    \"min_samples_split\": [2, 4, 6],\n",
    "    \"min_samples_leaf\": [1, 2, 3],\n",
    "    \"random_state\": [42],\n",
    "}\n",
    "\n",
    "best_dt_model = logistic_regression_model(\n",
    "    df,\n",
    "    DecisionTreeClassifier,\n",
    "    full_grid_search=True,\n",
    "    param_grid=dt_param_grid,\n",
    "    max_depth=3,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    random_state=42,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results df\n",
    "results.to_csv(\"../results/sklearn_results.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
