{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "sys.path.insert(0, '../utils')\n",
    "import utils\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import csv to df\n",
    "df = pd.read_csv('../data/renttherunway_cleaned_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit                object\n",
      "user_id             int64\n",
      "bust size          object\n",
      "item_id             int64\n",
      "weight            float64\n",
      "rating            float64\n",
      "rented for         object\n",
      "review_text        object\n",
      "body type          object\n",
      "review_summary     object\n",
      "category           object\n",
      "height            float64\n",
      "size                int64\n",
      "age               float64\n",
      "review_date        object\n",
      "review_length       int64\n",
      "band_size         float64\n",
      "cup_size           object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def logistic_regression_model(data):\n",
    "#     # Label Encoding for categorical variables\n",
    "#     label_encoders = {}\n",
    "#     categorical_cols = ['bust size', 'rented for', 'body type', 'category', 'cup_size']\n",
    "#     for col in categorical_cols:\n",
    "#         le = LabelEncoder()\n",
    "#         data[col] = le.fit_transform(data[col].astype(str))\n",
    "#         label_encoders[col] = le\n",
    "\n",
    "#     # Feature columns (excluding text and target columns)\n",
    "#     feature_cols = [col for col in data.columns if col not in ['fit', 'review_text', 'review_summary', 'review_date']]\n",
    "\n",
    "#     # Impute missing values\n",
    "#     imputer = SimpleImputer(strategy='mean')\n",
    "#     data[feature_cols] = imputer.fit_transform(data[feature_cols])\n",
    "\n",
    "#     # Splitting the dataset\n",
    "#     X = data[feature_cols]  # feature_cols defined in previous code\n",
    "#     y = data['fit'].apply(lambda x: 1 if x == 'fit' else 0)\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "#     # Scaling features\n",
    "#     scaler = StandardScaler()\n",
    "#     X_train = scaler.fit_transform(X_train)\n",
    "#     X_test = scaler.transform(X_test)\n",
    "\n",
    "#     # Logistic Regression Model\n",
    "#     model = LogisticRegression()\n",
    "\n",
    "#     # Hyperparameter Grid\n",
    "#     param_grid = {\n",
    "#         'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "#         'penalty': ['l1', 'l2'],\n",
    "#         'solver': ['liblinear']\n",
    "#     }\n",
    "\n",
    "#     # Grid Search with Cross-Validation\n",
    "#     grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy')\n",
    "#     grid_search.fit(X_train, y_train)\n",
    "\n",
    "#     best_model = grid_search.best_estimator_\n",
    "#     print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "#     print(f\"Best cross-validation score: {grid_search.best_score_}\")\n",
    "\n",
    "#     # Evaluate on test set\n",
    "#     test_score = best_model.score(X_test, y_test)\n",
    "#     print(f\"Test set score: {test_score}\")\n",
    "\n",
    "#     return best_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = logistic_regression_model(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def logistic_regression_model(data):\n",
    "#     # Label Encoding for categorical variables\n",
    "#     label_encoders = {}\n",
    "#     categorical_cols = ['bust size', 'rented for', 'body type', 'category', 'cup_size', 'fit']\n",
    "#     for col in categorical_cols:\n",
    "#         le = LabelEncoder()\n",
    "#         data[col] = le.fit_transform(data[col].astype(str))\n",
    "#         label_encoders[col] = le\n",
    "\n",
    "#     # Feature columns (excluding text and target columns)\n",
    "#     feature_cols = [col for col in data.columns if col not in ['review_text', 'review_summary', 'review_date']]\n",
    "\n",
    "#     # Impute missing values\n",
    "#     imputer = SimpleImputer(strategy='mean')\n",
    "#     data[feature_cols] = imputer.fit_transform(data[feature_cols])\n",
    "\n",
    "#     data = data.dropna(subset=['rating'])\n",
    "\n",
    "#     # Splitting the dataset\n",
    "#     X = data[feature_cols]  # feature_cols defined in previous code\n",
    "#     def map_rating_to_label(rating):\n",
    "#         rating_mapping = {2.0: 0, 4.0: 1, 6.0: 2, 8.0: 3, 10.0: 4}\n",
    "#         return rating_mapping.get(rating, 5)  # 5 is the label for 'others'\n",
    "\n",
    "#     y = data['rating'].apply(map_rating_to_label)\n",
    "    \n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "#     # Scaling features\n",
    "#     scaler = StandardScaler()\n",
    "#     X_train = scaler.fit_transform(X_train)\n",
    "#     X_test = scaler.transform(X_test)\n",
    "\n",
    "#     # Logistic Regression Model\n",
    "#     model = LogisticRegression()\n",
    "\n",
    "#     # Hyperparameter Grid\n",
    "#     param_grid = {\n",
    "#         'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "#         'penalty': ['l1', 'l2'],\n",
    "#         'solver': ['liblinear']\n",
    "#     }\n",
    "\n",
    "#     # Grid Search with Cross-Validation\n",
    "#     grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy')\n",
    "#     grid_search.fit(X_train, y_train)\n",
    "\n",
    "#     best_model = grid_search.best_estimator_\n",
    "#     print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "#     print(f\"Best cross-validation score: {grid_search.best_score_}\")\n",
    "\n",
    "#     # Evaluate on test set\n",
    "#     test_score = best_model.score(X_test, y_test)\n",
    "#     print(f\"Test set score: {test_score}\")\n",
    "\n",
    "#     return best_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic_regression_model(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearchCV for Ratings prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score, roc_auc_score, confusion_matrix, precision_score, recall_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "def logistic_regression_model(data):\n",
    "    # Label Encoding for categorical variables\n",
    "    label_encoders = {}\n",
    "    categorical_cols = ['bust size', 'rented for', 'body type', 'category', 'cup_size', 'fit']\n",
    "    for col in categorical_cols:\n",
    "        le = LabelEncoder()\n",
    "        data[col] = le.fit_transform(data[col].astype(str))\n",
    "        label_encoders[col] = le\n",
    "\n",
    "    # Feature columns (excluding text and target columns)\n",
    "    # feature_cols = ['rented for', 'body type', 'category', 'height', 'size', 'age', 'review_length', 'band_size','cup_size', 'fit']\n",
    "    feature_cols = ['fit', 'user_id', 'bust size', 'item_id', 'weight', 'rented for', 'body type', 'category', 'height', 'size', 'age', 'review_length', 'band_size', 'cup_size']\n",
    "    # feature_cols = [col for col in data.columns if col not in ['review_text', 'review_summary', 'review_date']]\n",
    "    # print(feature_cols)\n",
    "\n",
    "    # Impute missing values\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    data[feature_cols] = imputer.fit_transform(data[feature_cols])\n",
    "\n",
    "    data = data.dropna(subset=['rating'])\n",
    "\n",
    "    # Splitting the dataset\n",
    "    X = data[feature_cols]\n",
    "    def map_rating_to_label(rating):\n",
    "        rating_mapping = {2.0: 0, 4.0: 1, 6.0: 2, 8.0: 3, 10.0: 4}\n",
    "        return rating_mapping.get(rating, 5)  # 5 is the label for 'others'\n",
    "\n",
    "    y = data['rating'].apply(map_rating_to_label)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "    # Scaling features\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    # Logistic Regression Model\n",
    "    # model = LogisticRegression()\n",
    "    model = LogisticRegression()\n",
    "\n",
    "\n",
    "    # Hyperparameter Grid\n",
    "    # param_grid = {\n",
    "    #     'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    #     'penalty': ['l1', 'l2'],\n",
    "    #     'solver': ['liblinear']\n",
    "    # }\n",
    "    param_grid = {\n",
    "        # 'C': [10],\n",
    "        # 'penalty': ['l1'],\n",
    "        # 'solver': ['liblinear'],\n",
    "        'C': [0.01, 0.1, 1, 10, 100],  # Regularization strength\n",
    "        'penalty': ['l1', 'l2'],  # Penalty types\n",
    "        'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],  # Solvers\n",
    "        'class_weight': [\n",
    "            {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 1},  # Equal weights\n",
    "            {0: 2, 1: 1, 2: 1, 3: 1, 4: 1, 5: 1},  # Higher weight for class 0\n",
    "            {0: 1, 1: 2, 2: 1, 3: 1, 4: 1, 5: 1},  # Higher weight for class 1\n",
    "            {0: 1, 1: 1, 2: 2, 3: 1, 4: 1, 5: 1},  # Higher weight for class 2\n",
    "            {0: 1, 1: 1, 2: 1, 3: 2, 4: 1, 5: 1},  # Higher weight for class 3\n",
    "            {0: 1, 1: 1, 2: 1, 3: 1, 4: 2, 5: 1},  # Higher weight for class 4\n",
    "            {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 2},  # Higher weight for class 5\n",
    "            {0: 3, 1: 2, 2: 1, 3: 1, 4: 1, 5: 1},  # Custom weights as an example\n",
    "            'balanced'  # Automatically compute weights based on class frequencies\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    # Grid Search with Cross-Validation\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy', verbose=1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    best_model = grid_search.best_estimator_\n",
    "    print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "    print(f\"Best cross-validation score: {grid_search.best_score_}\")\n",
    "\n",
    "    # Evaluate on test set\n",
    "    test_score = best_model.score(X_test, y_test)\n",
    "    print(f\"Accuracy: {test_score}\")\n",
    "\n",
    "    # Print MSE and BER\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    print(f\"MSE: {np.mean((y_test - y_pred)**2)}\")\n",
    "    print(f\"BER: {1 - test_score}\")\n",
    "\n",
    "    # F1, AUC ROC, and Confusion Matrix, precision, recall\n",
    "    print(f\"F1 Score: {f1_score(y_test, y_pred, average='weighted')}\")\n",
    "    # print(f\"AUC ROC: {roc_auc_score(y_test, y_pred, multi_class='ovr', average='weighted')}\")\n",
    "    print(f\"Confusion Matrix: \\n{confusion_matrix(y_test, y_pred)}\")\n",
    "    print(f\"Precision: {precision_score(y_test, y_pred, average='weighted')}\")\n",
    "    print(f\"Recall: {recall_score(y_test, y_pred, average='weighted')}\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
    "\n",
    "    # Feature Importance Analysis\n",
    "    # Get coefficients and calculate odds ratios\n",
    "    coefficients = best_model.coef_[0]\n",
    "    odds_ratios = np.exp(coefficients)\n",
    "\n",
    "    # Create a DataFrame to display feature names and their corresponding odds ratios\n",
    "    feature_importance = pd.DataFrame()\n",
    "    feature_importance['feature'] = feature_cols\n",
    "    feature_importance['odds_ratio'] = odds_ratios\n",
    "\n",
    "    # Sort by odds_ratio to identify the most impactful feature\n",
    "    most_impactful_feature = feature_importance.sort_values(by='odds_ratio', ascending=False)\n",
    "    print(\"\\nMost Impactful Features (based on odds ratios):\")\n",
    "    print(most_impactful_feature)\n",
    "\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n",
      "Best parameters: {'C': 10, 'class_weight': {0: 1, 1: 1, 2: 1, 3: 2, 4: 2, 5: 2}, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Best cross-validation score: 0.6466304876547403\n",
      "Accuracy: 0.642442716361558\n",
      "MSE: 0.7049308093316475\n",
      "BER: 0.35755728363844197\n",
      "F1 Score: 0.5321629006228377\n",
      "Confusion Matrix: \n",
      "[[    0     0     0    43   292]\n",
      " [    0     0     0    77   774]\n",
      " [    0     0     0   248  2970]\n",
      " [    0     0     0   956 15163]\n",
      " [    0     0     0  1078 36138]]\n",
      "Precision: 0.5320392355135318\n",
      "Recall: 0.642442716361558\n",
      "Accuracy: 0.642442716361558\n",
      "\n",
      "Most Impactful Features (based on odds ratios):\n",
      "          feature  odds_ratio\n",
      "0             fit    2.146001\n",
      "10            age    1.144901\n",
      "7        category    1.098028\n",
      "2       bust size    1.074440\n",
      "1         user_id    1.072619\n",
      "12      band_size    1.041507\n",
      "4          weight    1.004582\n",
      "9            size    0.980962\n",
      "6       body type    0.970104\n",
      "13       cup_size    0.964263\n",
      "8          height    0.932176\n",
      "5      rented for    0.846021\n",
      "3         item_id    0.837734\n",
      "11  review_length    0.619739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mcgin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "best_model = logistic_regression_model(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
