{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "sys.path.insert(0, '../utils')\n",
    "import utils\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import csv to df\n",
    "df = pd.read_csv('../data/renttherunway_cleaned_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit                object\n",
      "user_id             int64\n",
      "bust size          object\n",
      "item_id             int64\n",
      "weight            float64\n",
      "rating            float64\n",
      "rented for         object\n",
      "review_text        object\n",
      "body type          object\n",
      "review_summary     object\n",
      "category           object\n",
      "height            float64\n",
      "size                int64\n",
      "age               float64\n",
      "review_date        object\n",
      "review_length       int64\n",
      "band_size         float64\n",
      "cup_size           object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression_model(data):\n",
    "    # Label Encoding for categorical variables\n",
    "    label_encoders = {}\n",
    "    categorical_cols = ['bust size', 'rented for', 'body type', 'category', 'cup_size']\n",
    "    for col in categorical_cols:\n",
    "        le = LabelEncoder()\n",
    "        data[col] = le.fit_transform(data[col].astype(str))\n",
    "        label_encoders[col] = le\n",
    "\n",
    "    # Feature columns (excluding text and target columns)\n",
    "    feature_cols = [col for col in data.columns if col not in ['fit', 'review_text', 'review_summary', 'review_date']]\n",
    "\n",
    "    # Impute missing values\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    data[feature_cols] = imputer.fit_transform(data[feature_cols])\n",
    "\n",
    "    # Splitting the dataset\n",
    "    X = data[feature_cols]  # feature_cols defined in previous code\n",
    "    y = data['fit'].apply(lambda x: 1 if x == 'fit' else 0)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "    # Scaling features\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    # Logistic Regression Model\n",
    "    model = LogisticRegression()\n",
    "\n",
    "    # Hyperparameter Grid\n",
    "    param_grid = {\n",
    "        'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "        'penalty': ['l1', 'l2'],\n",
    "        'solver': ['liblinear']\n",
    "    }\n",
    "\n",
    "    # Grid Search with Cross-Validation\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    best_model = grid_search.best_estimator_\n",
    "    print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "    print(f\"Best cross-validation score: {grid_search.best_score_}\")\n",
    "\n",
    "    # Evaluate on test set\n",
    "    test_score = best_model.score(X_test, y_test)\n",
    "    print(f\"Test set score: {test_score}\")\n",
    "\n",
    "    return best_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 0.01, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Best cross-validation score: 0.7478631844487312\n",
      "Test set score: 0.7436811855134686\n"
     ]
    }
   ],
   "source": [
    "model = logistic_regression_model(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression_model(data):\n",
    "    # Label Encoding for categorical variables\n",
    "    label_encoders = {}\n",
    "    categorical_cols = ['bust size', 'rented for', 'body type', 'category', 'cup_size', 'fit']\n",
    "    for col in categorical_cols:\n",
    "        le = LabelEncoder()\n",
    "        data[col] = le.fit_transform(data[col].astype(str))\n",
    "        label_encoders[col] = le\n",
    "\n",
    "    # Feature columns (excluding text and target columns)\n",
    "    feature_cols = [col for col in data.columns if col not in ['review_text', 'review_summary', 'review_date']]\n",
    "\n",
    "    # Impute missing values\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    data[feature_cols] = imputer.fit_transform(data[feature_cols])\n",
    "\n",
    "    data = data.dropna(subset=['rating'])\n",
    "\n",
    "    # Splitting the dataset\n",
    "    X = data[feature_cols]  # feature_cols defined in previous code\n",
    "    def map_rating_to_label(rating):\n",
    "        rating_mapping = {2.0: 0, 4.0: 1, 6.0: 2, 8.0: 3, 10.0: 4}\n",
    "        return rating_mapping.get(rating, 5)  # 5 is the label for 'others'\n",
    "\n",
    "    y = data['rating'].apply(map_rating_to_label)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "    # Scaling features\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    # Logistic Regression Model\n",
    "    model = LogisticRegression()\n",
    "\n",
    "    # Hyperparameter Grid\n",
    "    param_grid = {\n",
    "        'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "        'penalty': ['l1', 'l2'],\n",
    "        'solver': ['liblinear']\n",
    "    }\n",
    "\n",
    "    # Grid Search with Cross-Validation\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    best_model = grid_search.best_estimator_\n",
    "    print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "    print(f\"Best cross-validation score: {grid_search.best_score_}\")\n",
    "\n",
    "    # Evaluate on test set\n",
    "    test_score = best_model.score(X_test, y_test)\n",
    "    print(f\"Test set score: {test_score}\")\n",
    "\n",
    "    return best_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic_regression_model(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearchCV for Ratings prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "def logistic_regression_model(data):\n",
    "    # Label Encoding for categorical variables\n",
    "    label_encoders = {}\n",
    "    categorical_cols = ['bust size', 'rented for', 'body type', 'category', 'cup_size', 'fit']\n",
    "    for col in categorical_cols:\n",
    "        le = LabelEncoder()\n",
    "        data[col] = le.fit_transform(data[col].astype(str))\n",
    "        label_encoders[col] = le\n",
    "\n",
    "    # Feature columns (excluding text and target columns)\n",
    "    feature_cols = [col for col in data.columns if col not in ['review_text', 'review_summary', 'review_date']]\n",
    "\n",
    "    # Impute missing values\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    data[feature_cols] = imputer.fit_transform(data[feature_cols])\n",
    "\n",
    "    data = data.dropna(subset=['rating'])\n",
    "\n",
    "    # Splitting the dataset\n",
    "    X = data[feature_cols]\n",
    "    def map_rating_to_label(rating):\n",
    "        rating_mapping = {2.0: 0, 4.0: 1, 6.0: 2, 8.0: 3, 10.0: 4}\n",
    "        return rating_mapping.get(rating, 5)  # 5 is the label for 'others'\n",
    "\n",
    "    y = data['rating'].apply(map_rating_to_label)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "    # Scaling features\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    # Logistic Regression Model\n",
    "    model = LogisticRegression()\n",
    "\n",
    "    # Hyperparameter Grid\n",
    "    param_grid = {\n",
    "        'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "        'penalty': ['l1', 'l2'],\n",
    "        'solver': ['liblinear']\n",
    "    }\n",
    "\n",
    "    # Grid Search with Cross-Validation\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    best_model = grid_search.best_estimator_\n",
    "    print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "    print(f\"Best cross-validation score: {grid_search.best_score_}\")\n",
    "\n",
    "    # Evaluate on test set\n",
    "    test_score = best_model.score(X_test, y_test)\n",
    "    print(f\"Test set score: {test_score}\")\n",
    "\n",
    "    return best_model\n",
    "\n",
    "# Call the function with your data\n",
    "# best_model = logistic_regression_model(your_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mcgin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 10, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Best cross-validation score: 0.9297892862442501\n",
      "Test set score: 0.9289003531611384\n"
     ]
    }
   ],
   "source": [
    "best_model = logistic_regression_model(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
